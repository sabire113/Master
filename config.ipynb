{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7994d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded from config.py\n"
     ]
    }
   ],
   "source": [
    "# --- config.py ---\n",
    "# Central configuration file for the ML Asset Pricing Pipeline.\n",
    "# Edit the settings below to match your data, desired models, and analysis parameters.\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# <<< FILE PATHS >>>\n",
    "# --------------------------------------------------------------------------\n",
    "# *** POINT TO THE PREPROCESSED FILE ***\n",
    "DATA_FILE = \"Cleaned_OSEFX_Market_Macro_Data_PREPROCESSED.csv\"\n",
    "BENCHMARK_FILE = None\n",
    "FF_FACTOR_FILE = \"Europe_4_Factors_Monthly.csv\" # <--- Path to Fama-French factor CSV (optional)\n",
    "PORTFOLIO_DEFS_FILE = None\n",
    "OUTPUT_DIR = \"ML_Pipeline_Results_Yearly_Percentile_Preprocessed\" # Changed output dir name\n",
    "\n",
    "# <<< DATA PREPARATION CONFIG >>>\n",
    "# --------------------------------------------------------------------------\n",
    "# --- Column Names (These should match names in the *PREPROCESSED* CSV) ---\n",
    "# *** SIMPLIFIED: Only map ID/Date if they aren't standard, target is defined below ***\n",
    "COLUMN_CONFIG = {\n",
    "    'date': ['Date', 'date'],\n",
    "    'id': ['Instrument', 'instrument'],\n",
    "    # Other columns should now have clean names from preprocess_data.py\n",
    "    # We don't need mappings for price, shares, rf, book_market etc. here\n",
    "    # as they are either used in preprocessing or already logged/transformed.\n",
    "    'EconomicSector': ['EconomicSector'] # Keep if sector dummies are needed\n",
    "}\n",
    "\n",
    "# --- Feature Engineering (Now done externally) ---\n",
    "# VARS_TO_LOG = [] # Logging is done in preprocess_data.py\n",
    "TARGET_VARIABLE = \"TargetReturn_t+1\"         # *** MATCHES PREPROCESSING SCRIPT OUTPUT ***\n",
    "NEXT_RETURN_VARIABLE = \"NextMonthlyReturn_t+1\" # *** MATCHES PREPROCESSING SCRIPT OUTPUT ***\n",
    "MARKET_CAP_ORIG_VARIABLE = \"MarketCap_orig\"    # *** MATCHES PREPROCESSING SCRIPT OUTPUT ***\n",
    "\n",
    "# --- Data Cleaning & Filtering (Within Pipeline) ---\n",
    "# WINSORIZE_LIMITS = [] # Winsorizing of raw returns done externally\n",
    "# Imputation will happen in clean_data on features\n",
    "# Dropping NaNs focuses on target/ID/next_ret/mkt_cap_orig (essentials for modeling/analysis)\n",
    "ESSENTIAL_COLS_FOR_DROPNA = ['Date', 'Instrument', TARGET_VARIABLE, NEXT_RETURN_VARIABLE, MARKET_CAP_ORIG_VARIABLE]\n",
    "\n",
    "# <<< ROLLING WINDOW CONFIG >>>\n",
    "# --------------------------------------------------------------------------\n",
    "INITIAL_TRAIN_YEARS = 9\n",
    "VALIDATION_YEARS = 6\n",
    "TEST_YEARS_PER_WINDOW = 1\n",
    "\n",
    "# <<< MODEL CONFIGURATION >>>\n",
    "# --------------------------------------------------------------------------\n",
    "# --- Model Selection ---\n",
    "RUN_MODELS = {\n",
    "    'OLS': True,        'OLS3H': True,      'PLS': True,        'PCR': True,\n",
    "    'ENET': True,       'GLM_H': True,      'RF': True,         'GBRT_H': True,\n",
    "    'NN1': False,        'NN2': False,        'NN3': False,         'NN4': False,\n",
    "    'NN5': False,\n",
    "}\n",
    "\n",
    "# --- Feature Sets ---\n",
    "# *** THESE MUST MATCH THE COLUMN NAMES IN THE *PREPROCESSED* CSV ***\n",
    "OLS3_FEATURE_NAMES = [\"log_BM\", \"Momentum_12M\", \"log_MarketCap\"] # Verify these exist in the preprocessed file\n",
    "MODEL_FEATURE_MAP = { # Which feature set does each model use?\n",
    "    'OLS': 'all_numeric', 'OLS3H': 'ols3_features', 'PLS': 'all_numeric',\n",
    "    'PCR': 'all_numeric', 'ENET': 'all_numeric', 'GLM_H': 'all_numeric',\n",
    "    'RF': 'all_numeric', 'GBRT_H': 'all_numeric',\n",
    "    'NN1': 'all_numeric', 'NN2': 'all_numeric', 'NN3': 'all_numeric',\n",
    "    'NN4': 'all_numeric', 'NN5': 'all_numeric',\n",
    "}\n",
    "\n",
    "# --- Model Hyperparameters (Keep as is, or adjust) ---\n",
    "MODEL_PARAMS = {\n",
    "    'OLS': {},\n",
    "    'OLS3H': {'maxiter': 100, 'tol': 1e-6},\n",
    "    'PLS': {'n_components_grid': [1, 3, 5, 8, 10, 15]},\n",
    "    'PCR': {'n_components_grid': [1, 5, 10, 15, 20, 25]},\n",
    "    'ENET': {'alphas': np.logspace(-6, 1, 8), 'l1_ratio': [0.1, 0.5, 0.9, 0.99, 1.0], 'cv_folds': 3, 'max_iter': 1000, 'tol': 0.001, 'n_jobs': -1},\n",
    "    'GLM_H': {'param_grid': {'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0], 'epsilon': [1.1, 1.35, 1.5, 2.0]}, 'max_iter': 300},\n",
    "    'RF': {'param_grid': {'n_estimators': [100], 'max_depth': [3, 6, 10], 'min_samples_leaf': [50, 100], 'max_features': ['sqrt', 0.33]}, 'n_jobs': -1, 'random_state': 42},\n",
    "    'GBRT_H': {'param_grid': {'n_estimators': [100], 'learning_rate': [0.1], 'max_depth': [3, 5], 'min_samples_leaf': [50, 100], 'alpha': [0.9]}, 'loss': 'huber', 'random_state': 42},\n",
    "    'NN_SHARED': {'param_grid': {'lambda1': [1e-5, 1e-4, 1e-3], 'learning_rate': [0.001, 0.01]}, 'epochs': 100, 'batch_size': 10000, 'patience': 5, 'ensemble_size': 10, 'random_seed_base': 42},\n",
    "    'NN1': {'name': 'NN1', 'hidden_units': [32]},\n",
    "    'NN2': {'name': 'NN2', 'hidden_units': [64, 32]},\n",
    "    'NN3': {'name': 'NN3', 'hidden_units': [96, 64, 32]},\n",
    "    'NN4': {'name': 'NN4', 'hidden_units': [128, 96, 64, 32]},\n",
    "    'NN5': {'name': 'NN5', 'hidden_units': [128, 96, 64, 32, 16]},\n",
    "}\n",
    "\n",
    "# <<< ANALYSIS & REPORTING CONFIG >>>\n",
    "# --------------------------------------------------------------------------\n",
    "SUBSETS_TO_RUN = ['all', 'big', 'small']\n",
    "BIG_FIRM_TOP_PERCENT = 30\n",
    "SMALL_FIRM_BOTTOM_PERCENT = 30\n",
    "# Use the specific market cap column saved for this purpose\n",
    "FILTER_SMALL_CAPS_PORTFOLIO = False\n",
    "ANNUALIZATION_FACTOR = 12\n",
    "\n",
    "# --- Variable Importance ---\n",
    "CALCULATE_VI = True\n",
    "VI_METHOD = 'permutation_zero'\n",
    "VI_PLOT_TOP_N = 20\n",
    "MODEL_VI_STRATEGY = {\n",
    "    'OLS': 'per_window', 'OLS3H': 'per_window', 'PLS': 'per_window',\n",
    "    'PCR': 'per_window', 'ENET': 'per_window', 'GLM_H': 'per_window',\n",
    "    'RF': 'last_window', 'GBRT_H': 'last_window',\n",
    "    'NN1': 'last_window', 'NN2': 'last_window', 'NN3': 'last_window',\n",
    "    'NN4': 'last_window', 'NN5': 'last_window',\n",
    "}\n",
    "\n",
    "# --- Complexity Plotting ---\n",
    "COMPLEXITY_PARAMS_TO_PLOT = {\n",
    "    'PLS': ['optim_n_components'], 'PCR': ['optim_n_components'],\n",
    "    'ENET': ['optim_alpha', 'optim_l1_ratio'], 'GLM_H': ['optim_alpha', 'optim_epsilon'],\n",
    "    'RF': ['optim_max_depth'],\n",
    "    'GBRT_H': ['optim_max_depth'],\n",
    "    'NN1': ['optim_lambda1', 'optim_learning_rate'], 'NN2': ['optim_lambda1', 'optim_learning_rate'],\n",
    "    'NN3': ['optim_lambda1', 'optim_learning_rate'], 'NN4': ['optim_lambda1', 'optim_learning_rate'],\n",
    "    'NN5': ['optim_lambda1', 'optim_learning_rate'],\n",
    "}\n",
    "\n",
    "# --- Seeds ---\n",
    "GENERAL_SEED = 42\n",
    "TF_SEED = 42\n",
    "\n",
    "# --- Create Output Directory ---\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    print(f\"Created output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "print(\"Configuration loaded from config.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
