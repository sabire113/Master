{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabire113/Master/blob/main/Neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0e6be92",
      "metadata": {
        "id": "a0e6be92"
      },
      "source": [
        "# Neural network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "cYHik7I7T4R2",
        "outputId": "d2bfab26-4e9b-4019-8e68-b94780a21f65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "id": "cYHik7I7T4R2",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4249a31e-ec9e-4e80-a9f5-5972c91b95bc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4249a31e-ec9e-4e80-a9f5-5972c91b95bc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving OSEBX_Market_Macro_Data_2015_2024.csv to OSEBX_Market_Macro_Data_2015_2024.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3df330b4",
      "metadata": {
        "scrolled": true,
        "id": "3df330b4",
        "outputId": "35137b01-fea7-4a7b-b6dd-b460fd8dc50a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7080 entries, 0 to 7079\n",
            "Data columns (total 34 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   Date                     7080 non-null   object \n",
            " 1   Instrument               7080 non-null   object \n",
            " 2   First Trade Date         7080 non-null   object \n",
            " 3   ClosePrice               7080 non-null   float64\n",
            " 4   OpenPrice                7080 non-null   float64\n",
            " 5   Volume                   7080 non-null   float64\n",
            " 6   BidPrice                 7080 non-null   float64\n",
            " 7   AskPrice                 7080 non-null   float64\n",
            " 8   DividendYield            7079 non-null   float64\n",
            " 9   BookValuePerShare        7080 non-null   float64\n",
            " 10  Beta                     7069 non-null   float64\n",
            " 11  MarketCap                7080 non-null   float64\n",
            " 12  CommonSharesOutstanding  7080 non-null   float64\n",
            " 13  MonthlyReturn            7080 non-null   float64\n",
            " 14  EconomicSector           7080 non-null   object \n",
            " 15  EarningsPerShare         7080 non-null   float64\n",
            " 16  RIC                      7080 non-null   object \n",
            " 17  Momentum_3M              7077 non-null   float64\n",
            " 18  Momentum_6M              7074 non-null   float64\n",
            " 19  Momentum_12M             7068 non-null   float64\n",
            " 20  Volatility_3M            7079 non-null   float64\n",
            " 21  Volatility_6M            7079 non-null   float64\n",
            " 22  Volatility_12M           7079 non-null   float64\n",
            " 23  BidAskSpread             7080 non-null   float64\n",
            " 24  TurnoverRatio            7080 non-null   float64\n",
            " 25  BrentOil                 7080 non-null   float64\n",
            " 26  USDNOK                   7080 non-null   float64\n",
            " 27  EURNOK                   7080 non-null   float64\n",
            " 28  US10Y                    7080 non-null   float64\n",
            " 29  USCPI                    7080 non-null   float64\n",
            " 30  USGDPGrowth              7080 non-null   float64\n",
            " 31  OSEBXReturns             7079 non-null   float64\n",
            " 32  NorgesBank10Y            7080 non-null   float64\n",
            " 33  NorwegianCPI             7080 non-null   float64\n",
            "dtypes: float64(29), object(5)\n",
            "memory usage: 1.8+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,\n",
              "          Date Instrument First Trade Date  ClosePrice   OpenPrice   Volume  \\\n",
              " 0  2015-01-31    AFGA.OL       1997-09-08   79.420230   79.890172      0.0   \n",
              " 1  2015-02-28    AFGA.OL       1997-09-08   85.059536   85.529479      0.0   \n",
              " 2  2015-03-31    AFGA.OL       1997-09-08   93.048554   93.988438  29730.0   \n",
              " 3  2015-04-30    AFGA.OL       1997-09-08   97.747976   93.988438  31574.0   \n",
              " 4  2015-05-31    AFGA.OL       1997-09-08  105.267051  100.567629      0.0   \n",
              " \n",
              "      BidPrice    AskPrice  DividendYield  BookValuePerShare  ...  \\\n",
              " 0   79.420230   80.595086            NaN          15.058302  ...   \n",
              " 1   84.354623   85.059536       5.524862          15.723256  ...   \n",
              " 2   92.578611   93.518496       5.050505          15.723256  ...   \n",
              " 3   96.808091   97.747976       4.807692          15.723256  ...   \n",
              " 4  104.327166  105.267051       4.464286          15.723256  ...   \n",
              " \n",
              "    TurnoverRatio   BrentOil    USDNOK    EURNOK US10Y    USCPI USGDPGrowth  \\\n",
              " 0       0.000000  52.990002  7.725400  8.725100  1.68  234.747         3.6   \n",
              " 1       0.000000  52.990002  7.682852  8.585165  2.00  235.342         3.6   \n",
              " 2       0.000335  52.990002  8.007700  8.672500  1.94  235.976         3.6   \n",
              " 3       0.000356  66.779999  7.523240  8.360700  2.05  236.222         2.5   \n",
              " 4       0.000000  65.559998  7.791610  8.543300  2.12  237.001         2.5   \n",
              " \n",
              "    OSEBXReturns  NorgesBank10Y  NorwegianCPI  \n",
              " 0           NaN          1.512          98.5  \n",
              " 1      0.032624          1.421          98.9  \n",
              " 2      0.005783          1.565          99.2  \n",
              " 3      0.032558          1.453          99.6  \n",
              " 4      0.009885          1.695          99.8  \n",
              " \n",
              " [5 rows x 34 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"OSEBX_Market_Macro_Data_2015_2024.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display basic information and first few rows\n",
        "df.info(), df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "mKnihsROTpYy"
      },
      "id": "mKnihsROTpYy"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "31837702",
      "metadata": {
        "scrolled": true,
        "id": "31837702",
        "outputId": "44383a3d-6ba3-40d8-e9a5-217e4896babf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           Date Instrument First Trade Date  ClosePrice   OpenPrice  Volume  \\\n",
              "480  2015-01-31   AKSOA.OL       2014-09-29   24.114697   24.650013     0.0   \n",
              "2760 2015-01-31    FLNG.OL       2007-04-19   86.190732   86.190732     0.0   \n",
              "6600 2015-01-31     VEI.OL       1986-06-23   67.629914   67.841920     0.0   \n",
              "4800 2015-01-31    NYKD.OL       2020-01-27  100.450000  102.000000     0.0   \n",
              "600  2015-01-31    ATEA.OL       1985-03-28   75.787717   77.113450     0.0   \n",
              "...         ...        ...              ...         ...         ...     ...   \n",
              "5759 2024-12-31    SCHB.OL       2015-06-01  334.200000  332.600000     0.0   \n",
              "1559 2024-12-31   BWLPG.OL       2013-11-21  125.300000  127.000000     0.0   \n",
              "5879 2024-12-31     SNI.OL       1996-02-02  289.000000  292.000000     0.0   \n",
              "4919 2024-12-31    NYKD.OL       2020-01-27    3.046000    3.000000     0.0   \n",
              "7079 2024-12-31     YAR.OL       2004-03-25  300.800000  299.800000     0.0   \n",
              "\n",
              "        BidPrice    AskPrice  DividendYield  BookValuePerShare  ...  \\\n",
              "480    24.114697   24.197544      11.898241          22.904350  ...   \n",
              "2760   86.190732   88.653324      10.452511          16.617404  ...   \n",
              "6600   67.417908   67.629914      13.295551          17.980553  ...   \n",
              "4800   19.200000   19.200000       0.000000           3.134430  ...   \n",
              "600    75.566762   75.787717      73.954984          34.743722  ...   \n",
              "...          ...         ...            ...                ...  ...   \n",
              "5759  333.200000  334.200000      21.170455         185.422331  ...   \n",
              "1559  125.300000  125.400000      25.788244          11.047649  ...   \n",
              "5879  289.000000  290.000000      10.533452          35.611202  ...   \n",
              "4919    3.020000    3.046000       0.000000           0.569875  ...   \n",
              "7079  300.600000  300.800000       1.662234          29.647586  ...   \n",
              "\n",
              "      TurnoverRatio   BrentOil    USDNOK    EURNOK US10Y    USCPI USGDPGrowth  \\\n",
              "480             0.0  52.990002   7.72540   8.72510  1.68  234.747         3.6   \n",
              "2760            0.0  52.990002   7.72540   8.72510  1.68  234.747         3.6   \n",
              "6600            0.0  52.990002   7.72540   8.72510  1.68  234.747         3.6   \n",
              "4800            0.0  52.990002   7.72540   8.72510  1.68  234.747         3.6   \n",
              "600             0.0  52.990002   7.72540   8.72510  1.68  234.747         3.6   \n",
              "...             ...        ...       ...       ...   ...      ...         ...   \n",
              "5759            0.0  72.940002  11.32762  11.78811  4.58  317.603         2.3   \n",
              "1559            0.0  72.940002  11.32762  11.78811  4.58  317.603         2.3   \n",
              "5879            0.0  72.940002  11.32762  11.78811  4.58  317.603         2.3   \n",
              "4919            0.0  72.940002  11.32762  11.78811  4.58  317.603         2.3   \n",
              "7079            0.0  72.940002  11.32762  11.78811  4.58  317.603         2.3   \n",
              "\n",
              "      OSEBXReturns  NorgesBank10Y  NorwegianCPI  \n",
              "480      -0.020052          1.512          98.5  \n",
              "2760     -0.020052          1.512          98.5  \n",
              "6600     -0.020052          1.512          98.5  \n",
              "4800     -0.020052          1.512          98.5  \n",
              "600      -0.020052          1.512          98.5  \n",
              "...            ...            ...           ...  \n",
              "5759     -0.020052          3.599         137.6  \n",
              "1559     -0.020052          3.599         137.6  \n",
              "5879     -0.020052          3.599         137.6  \n",
              "4919     -0.020052          3.599         137.6  \n",
              "7079     -0.020052          3.599         137.6  \n",
              "\n",
              "[7068 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7159fe94-d298-4e90-a3f3-4fc1f7763453\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Instrument</th>\n",
              "      <th>First Trade Date</th>\n",
              "      <th>ClosePrice</th>\n",
              "      <th>OpenPrice</th>\n",
              "      <th>Volume</th>\n",
              "      <th>BidPrice</th>\n",
              "      <th>AskPrice</th>\n",
              "      <th>DividendYield</th>\n",
              "      <th>BookValuePerShare</th>\n",
              "      <th>...</th>\n",
              "      <th>TurnoverRatio</th>\n",
              "      <th>BrentOil</th>\n",
              "      <th>USDNOK</th>\n",
              "      <th>EURNOK</th>\n",
              "      <th>US10Y</th>\n",
              "      <th>USCPI</th>\n",
              "      <th>USGDPGrowth</th>\n",
              "      <th>OSEBXReturns</th>\n",
              "      <th>NorgesBank10Y</th>\n",
              "      <th>NorwegianCPI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>AKSOA.OL</td>\n",
              "      <td>2014-09-29</td>\n",
              "      <td>24.114697</td>\n",
              "      <td>24.650013</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.114697</td>\n",
              "      <td>24.197544</td>\n",
              "      <td>11.898241</td>\n",
              "      <td>22.904350</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.990002</td>\n",
              "      <td>7.72540</td>\n",
              "      <td>8.72510</td>\n",
              "      <td>1.68</td>\n",
              "      <td>234.747</td>\n",
              "      <td>3.6</td>\n",
              "      <td>-0.020052</td>\n",
              "      <td>1.512</td>\n",
              "      <td>98.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2760</th>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>FLNG.OL</td>\n",
              "      <td>2007-04-19</td>\n",
              "      <td>86.190732</td>\n",
              "      <td>86.190732</td>\n",
              "      <td>0.0</td>\n",
              "      <td>86.190732</td>\n",
              "      <td>88.653324</td>\n",
              "      <td>10.452511</td>\n",
              "      <td>16.617404</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.990002</td>\n",
              "      <td>7.72540</td>\n",
              "      <td>8.72510</td>\n",
              "      <td>1.68</td>\n",
              "      <td>234.747</td>\n",
              "      <td>3.6</td>\n",
              "      <td>-0.020052</td>\n",
              "      <td>1.512</td>\n",
              "      <td>98.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6600</th>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>VEI.OL</td>\n",
              "      <td>1986-06-23</td>\n",
              "      <td>67.629914</td>\n",
              "      <td>67.841920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.417908</td>\n",
              "      <td>67.629914</td>\n",
              "      <td>13.295551</td>\n",
              "      <td>17.980553</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.990002</td>\n",
              "      <td>7.72540</td>\n",
              "      <td>8.72510</td>\n",
              "      <td>1.68</td>\n",
              "      <td>234.747</td>\n",
              "      <td>3.6</td>\n",
              "      <td>-0.020052</td>\n",
              "      <td>1.512</td>\n",
              "      <td>98.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4800</th>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>NYKD.OL</td>\n",
              "      <td>2020-01-27</td>\n",
              "      <td>100.450000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.200000</td>\n",
              "      <td>19.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.134430</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.990002</td>\n",
              "      <td>7.72540</td>\n",
              "      <td>8.72510</td>\n",
              "      <td>1.68</td>\n",
              "      <td>234.747</td>\n",
              "      <td>3.6</td>\n",
              "      <td>-0.020052</td>\n",
              "      <td>1.512</td>\n",
              "      <td>98.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>ATEA.OL</td>\n",
              "      <td>1985-03-28</td>\n",
              "      <td>75.787717</td>\n",
              "      <td>77.113450</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.566762</td>\n",
              "      <td>75.787717</td>\n",
              "      <td>73.954984</td>\n",
              "      <td>34.743722</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.990002</td>\n",
              "      <td>7.72540</td>\n",
              "      <td>8.72510</td>\n",
              "      <td>1.68</td>\n",
              "      <td>234.747</td>\n",
              "      <td>3.6</td>\n",
              "      <td>-0.020052</td>\n",
              "      <td>1.512</td>\n",
              "      <td>98.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5759</th>\n",
              "      <td>2024-12-31</td>\n",
              "      <td>SCHB.OL</td>\n",
              "      <td>2015-06-01</td>\n",
              "      <td>334.200000</td>\n",
              "      <td>332.600000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>333.200000</td>\n",
              "      <td>334.200000</td>\n",
              "      <td>21.170455</td>\n",
              "      <td>185.422331</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.940002</td>\n",
              "      <td>11.32762</td>\n",
              "      <td>11.78811</td>\n",
              "      <td>4.58</td>\n",
              "      <td>317.603</td>\n",
              "      <td>2.3</td>\n",
              "      <td>-0.020052</td>\n",
              "      <td>3.599</td>\n",
              "      <td>137.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1559</th>\n",
              "      <td>2024-12-31</td>\n",
              "      <td>BWLPG.OL</td>\n",
              "      <td>2013-11-21</td>\n",
              "      <td>125.300000</td>\n",
              "      <td>127.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>125.300000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>25.788244</td>\n",
              "      <td>11.047649</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.940002</td>\n",
              "      <td>11.32762</td>\n",
              "      <td>11.78811</td>\n",
              "      <td>4.58</td>\n",
              "      <td>317.603</td>\n",
              "      <td>2.3</td>\n",
              "      <td>-0.020052</td>\n",
              "      <td>3.599</td>\n",
              "      <td>137.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5879</th>\n",
              "      <td>2024-12-31</td>\n",
              "      <td>SNI.OL</td>\n",
              "      <td>1996-02-02</td>\n",
              "      <td>289.000000</td>\n",
              "      <td>292.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>289.000000</td>\n",
              "      <td>290.000000</td>\n",
              "      <td>10.533452</td>\n",
              "      <td>35.611202</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.940002</td>\n",
              "      <td>11.32762</td>\n",
              "      <td>11.78811</td>\n",
              "      <td>4.58</td>\n",
              "      <td>317.603</td>\n",
              "      <td>2.3</td>\n",
              "      <td>-0.020052</td>\n",
              "      <td>3.599</td>\n",
              "      <td>137.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4919</th>\n",
              "      <td>2024-12-31</td>\n",
              "      <td>NYKD.OL</td>\n",
              "      <td>2020-01-27</td>\n",
              "      <td>3.046000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.020000</td>\n",
              "      <td>3.046000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.569875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.940002</td>\n",
              "      <td>11.32762</td>\n",
              "      <td>11.78811</td>\n",
              "      <td>4.58</td>\n",
              "      <td>317.603</td>\n",
              "      <td>2.3</td>\n",
              "      <td>-0.020052</td>\n",
              "      <td>3.599</td>\n",
              "      <td>137.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7079</th>\n",
              "      <td>2024-12-31</td>\n",
              "      <td>YAR.OL</td>\n",
              "      <td>2004-03-25</td>\n",
              "      <td>300.800000</td>\n",
              "      <td>299.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>300.600000</td>\n",
              "      <td>300.800000</td>\n",
              "      <td>1.662234</td>\n",
              "      <td>29.647586</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.940002</td>\n",
              "      <td>11.32762</td>\n",
              "      <td>11.78811</td>\n",
              "      <td>4.58</td>\n",
              "      <td>317.603</td>\n",
              "      <td>2.3</td>\n",
              "      <td>-0.020052</td>\n",
              "      <td>3.599</td>\n",
              "      <td>137.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7068 rows Ã— 34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7159fe94-d298-4e90-a3f3-4fc1f7763453')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7159fe94-d298-4e90-a3f3-4fc1f7763453 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7159fe94-d298-4e90-a3f3-4fc1f7763453');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4b17adc9-dda2-480a-b420-678dfa1d859a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b17adc9-dda2-480a-b420-678dfa1d859a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4b17adc9-dda2-480a-b420-678dfa1d859a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_62921254-9c50-4a7d-95fe-21abebef3986\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_clean')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_62921254-9c50-4a7d-95fe-21abebef3986 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_clean');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_clean"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Train Set': (3528, 22),\n",
              " 'Validation Set': (2124, 22),\n",
              " 'Test Set': (1416, 22),\n",
              " 'Target Variable': 'OSEBXReturns',\n",
              " 'Feature Count': 22}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Drop rows with missing target variable (OSEBXReturns)\n",
        "df_clean = df.dropna(subset=[\"OSEBXReturns\"]).copy()\n",
        "\n",
        "# Convert Date column to datetime format\n",
        "df_clean[\"Date\"] = pd.to_datetime(df_clean[\"Date\"])\n",
        "\n",
        "# Selecting Features (X) and Target (Y)\n",
        "features = [\n",
        "    \"Momentum_3M\", \"Momentum_6M\", \"Momentum_12M\",\n",
        "    \"Volatility_3M\", \"Volatility_6M\", \"Volatility_12M\",\n",
        "    \"Volume\", \"TurnoverRatio\", \"BidAskSpread\",\n",
        "    \"MarketCap\", \"DividendYield\", \"BookValuePerShare\",\n",
        "    \"EarningsPerShare\", \"Beta\", \"USDNOK\", \"EURNOK\",\n",
        "    \"US10Y\", \"USCPI\", \"USGDPGrowth\", \"NorgesBank10Y\", \"NorwegianCPI\",\n",
        "    \"BrentOil\"\n",
        "]\n",
        "\n",
        "target = \"OSEBXReturns\"\n",
        "\n",
        "# Drop remaining rows with missing features\n",
        "df_clean = df_clean.dropna(subset=features)\n",
        "\n",
        "# Sorting dataset by Date\n",
        "df_clean = df_clean.sort_values(by=\"Date\")\n",
        "\n",
        "# Splitting data into training (2015-2019), validation (2020-2022), and test (2023-2024)\n",
        "train = df_clean[(df_clean[\"Date\"].dt.year >= 2015) & (df_clean[\"Date\"].dt.year <= 2019)]\n",
        "valid = df_clean[(df_clean[\"Date\"].dt.year >= 2020) & (df_clean[\"Date\"].dt.year <= 2022)]\n",
        "test = df_clean[(df_clean[\"Date\"].dt.year >= 2023)]\n",
        "\n",
        "# Extract features and target\n",
        "X_train, y_train = train[features], train[target]\n",
        "X_valid, y_valid = valid[features], valid[target]\n",
        "X_test, y_test = test[features], test[target]\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrame\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=features, index=X_train.index)\n",
        "X_valid_scaled = pd.DataFrame(X_valid_scaled, columns=features, index=X_valid.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=features, index=X_test.index)\n",
        "\n",
        "# Display the cleaned and split dataset info\n",
        "display(df_clean)\n",
        "\n",
        "# Summary\n",
        "{\n",
        "    \"Train Set\": X_train_scaled.shape,\n",
        "    \"Validation Set\": X_valid_scaled.shape,\n",
        "    \"Test Set\": X_test_scaled.shape,\n",
        "    \"Target Variable\": target,\n",
        "    \"Feature Count\": len(features)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "81b9d448",
      "metadata": {
        "scrolled": false,
        "id": "81b9d448",
        "outputId": "0a2548f7-8560-4029-abe6-340955ecf20a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow scikit-learn pandas numpy matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "605f7924",
      "metadata": {
        "id": "605f7924",
        "outputId": "7569181a-b97a-4d59-b426-99172518e9c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 1.8483 - mae: 0.8675 - val_loss: 8.7090 - val_mae: 1.9806\n",
            "Epoch 2/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8057 - mae: 0.3858 - val_loss: 9.3910 - val_mae: 2.0790\n",
            "Epoch 3/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6514 - mae: 0.2673 - val_loss: 7.8976 - val_mae: 1.9135\n",
            "Epoch 4/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5746 - mae: 0.2086 - val_loss: 6.2019 - val_mae: 1.6743\n",
            "Epoch 5/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5187 - mae: 0.1732 - val_loss: 4.8642 - val_mae: 1.4690\n",
            "Epoch 6/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4713 - mae: 0.1483 - val_loss: 3.8897 - val_mae: 1.3060\n",
            "Epoch 7/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4284 - mae: 0.1295 - val_loss: 3.0718 - val_mae: 1.1372\n",
            "Epoch 8/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3887 - mae: 0.1156 - val_loss: 2.5408 - val_mae: 1.0199\n",
            "Epoch 9/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3514 - mae: 0.1051 - val_loss: 2.0754 - val_mae: 0.9014\n",
            "Epoch 10/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3161 - mae: 0.0964 - val_loss: 1.7653 - val_mae: 0.8158\n",
            "Epoch 11/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2826 - mae: 0.0888 - val_loss: 1.4914 - val_mae: 0.7242\n",
            "Epoch 12/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2510 - mae: 0.0823 - val_loss: 1.2091 - val_mae: 0.6289\n",
            "Epoch 13/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2215 - mae: 0.0763 - val_loss: 0.9903 - val_mae: 0.5566\n",
            "Epoch 14/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1942 - mae: 0.0719 - val_loss: 0.7887 - val_mae: 0.4782\n",
            "Epoch 15/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1689 - mae: 0.0667 - val_loss: 0.5479 - val_mae: 0.3714\n",
            "Epoch 16/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1457 - mae: 0.0613 - val_loss: 0.4827 - val_mae: 0.3515\n",
            "Epoch 17/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1250 - mae: 0.0574 - val_loss: 0.4521 - val_mae: 0.3428\n",
            "Epoch 18/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1065 - mae: 0.0540 - val_loss: 0.4054 - val_mae: 0.3126\n",
            "Epoch 19/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0900 - mae: 0.0506 - val_loss: 0.3503 - val_mae: 0.2815\n",
            "Epoch 20/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0754 - mae: 0.0469 - val_loss: 0.3085 - val_mae: 0.2583\n",
            "Epoch 21/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0627 - mae: 0.0436 - val_loss: 0.2628 - val_mae: 0.2343\n",
            "Epoch 22/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0518 - mae: 0.0404 - val_loss: 0.2219 - val_mae: 0.2148\n",
            "Epoch 23/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0425 - mae: 0.0380 - val_loss: 0.1609 - val_mae: 0.1813\n",
            "Epoch 24/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0346 - mae: 0.0356 - val_loss: 0.1410 - val_mae: 0.1669\n",
            "Epoch 25/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0280 - mae: 0.0335 - val_loss: 0.1204 - val_mae: 0.1540\n",
            "Epoch 26/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0226 - mae: 0.0321 - val_loss: 0.1058 - val_mae: 0.1446\n",
            "Epoch 27/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - mae: 0.0305 - val_loss: 0.0929 - val_mae: 0.1418\n",
            "Epoch 28/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0144 - mae: 0.0294 - val_loss: 0.0778 - val_mae: 0.1329\n",
            "Epoch 29/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0114 - mae: 0.0279 - val_loss: 0.0771 - val_mae: 0.1284\n",
            "Epoch 30/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0258 - val_loss: 0.0788 - val_mae: 0.1275\n",
            "Epoch 31/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0070 - mae: 0.0240 - val_loss: 0.0644 - val_mae: 0.1169\n",
            "Epoch 32/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0055 - mae: 0.0228 - val_loss: 0.0662 - val_mae: 0.1445\n",
            "Epoch 33/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0043 - mae: 0.0216 - val_loss: 0.0577 - val_mae: 0.1446\n",
            "Epoch 34/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0201 - val_loss: 0.0966 - val_mae: 0.2040\n",
            "Epoch 35/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0201 - val_loss: 0.1079 - val_mae: 0.2061\n",
            "Epoch 36/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - mae: 0.0179 - val_loss: 0.0999 - val_mae: 0.2161\n",
            "Epoch 37/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mae: 0.0178 - val_loss: 0.1196 - val_mae: 0.2362\n",
            "Epoch 38/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0173 - val_loss: 0.0882 - val_mae: 0.2094\n",
            "Epoch 39/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0170 - val_loss: 0.1388 - val_mae: 0.2304\n",
            "Epoch 40/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0010 - mae: 0.0167 - val_loss: 0.1826 - val_mae: 0.2327\n",
            "Epoch 41/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9.0361e-04 - mae: 0.0167 - val_loss: 0.2064 - val_mae: 0.2150\n",
            "Epoch 42/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.3217e-04 - mae: 0.0165 - val_loss: 0.2251 - val_mae: 0.2385\n",
            "Epoch 43/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7.9791e-04 - mae: 0.0169 - val_loss: 0.3268 - val_mae: 0.2501\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m67/67\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Train RÂ²: 0.2792\n",
            "Validation RÂ²: -16.3748\n",
            "Test RÂ² (Out-of-Sample): -225.7573\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Load your cleaned dataset (X_train_scaled, X_valid_scaled, etc.)\n",
        "# Ensure you have run the data preprocessing steps before this!\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define the Neural Network (NN3) Model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train_scaled.shape[1],)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(16, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(8, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(1, activation=\"linear\")  # Output layer (predicting excess return)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Train the model with early stopping\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_data=(X_valid_scaled, y_valid),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "y_train_pred = model.predict(X_train_scaled).flatten()\n",
        "y_valid_pred = model.predict(X_valid_scaled).flatten()\n",
        "y_test_pred = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "# Compute R-squared\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_valid = r2_score(y_valid, y_valid_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Print Results\n",
        "print(f\"Train RÂ²: {r2_train:.4f}\")\n",
        "print(f\"Validation RÂ²: {r2_valid:.4f}\")\n",
        "print(f\"Test RÂ² (Out-of-Sample): {r2_test:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow scikit-learn pandas numpy matplotlib\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/OSEBX_Market_Macro_Data_2015_2024.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "df = df.dropna(subset=[\"OSEBXReturns\"])  # Drop missing target values\n",
        "\n",
        "features = [\n",
        "    \"Momentum_3M\", \"Momentum_6M\", \"Momentum_12M\",\n",
        "    \"Volatility_3M\", \"Volatility_6M\", \"Volatility_12M\",\n",
        "    \"Volume\", \"TurnoverRatio\", \"BidAskSpread\",\n",
        "    \"MarketCap\", \"DividendYield\", \"BookValuePerShare\",\n",
        "    \"EarningsPerShare\", \"Beta\", \"USDNOK\", \"EURNOK\",\n",
        "    \"US10Y\", \"USCPI\", \"USGDPGrowth\", \"NorgesBank10Y\", \"NorwegianCPI\",\n",
        "    \"BrentOil\"\n",
        "]\n",
        "\n",
        "target = \"OSEBXReturns\"\n",
        "df = df.dropna(subset=features)  # Drop missing feature values\n",
        "\n",
        "# Splitting data by year\n",
        "df = df.sort_values(by=\"Date\")\n",
        "train = df[(df[\"Date\"].dt.year >= 2015) & (df[\"Date\"].dt.year <= 2019)]\n",
        "valid = df[(df[\"Date\"].dt.year >= 2020) & (df[\"Date\"].dt.year <= 2022)]\n",
        "test = df[(df[\"Date\"].dt.year >= 2023)]\n",
        "\n",
        "X_train, y_train = train[features], train[target]\n",
        "X_valid, y_valid = valid[features], valid[target]\n",
        "X_test, y_test = test[features], test[target]\n",
        "\n",
        "# Standardizing features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Feature Selection using Elastic Net and Random Forest\n",
        "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "elastic_net.fit(X_train_scaled, y_train)\n",
        "elastic_net_importance = abs(elastic_net.coef_)\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "rf_importance = rf.feature_importances_\n",
        "\n",
        "# Select Top Features\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    \"Feature\": features,\n",
        "    \"ElasticNet Importance\": elastic_net_importance,\n",
        "    \"RandomForest Importance\": rf_importance\n",
        "})\n",
        "\n",
        "feature_importance_df[\"Avg Importance\"] = (feature_importance_df[\"ElasticNet Importance\"] + feature_importance_df[\"RandomForest Importance\"]) / 2\n",
        "feature_importance_df = feature_importance_df.sort_values(by=\"Avg Importance\", ascending=False)\n",
        "\n",
        "top_features = feature_importance_df[\"Feature\"].head(10).tolist()\n",
        "\n",
        "X_train_selected = pd.DataFrame(X_train_scaled, columns=features)[top_features]\n",
        "X_valid_selected = pd.DataFrame(X_valid_scaled, columns=features)[top_features]\n",
        "X_test_selected = pd.DataFrame(X_test_scaled, columns=features)[top_features]\n",
        "\n",
        "# Define Updated Neural Network with Regularization\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(0.1), input_shape=(X_train_selected.shape[1],)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(16, activation=\"relu\", kernel_regularizer=regularizers.l2(0.1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(8, activation=\"relu\", kernel_regularizer=regularizers.l2(0.1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(1, activation=\"linear\")  # Output layer\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Train the model with Early Stopping\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_selected, y_train,\n",
        "    validation_data=(X_valid_selected, y_valid),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate Model\n",
        "y_train_pred = model.predict(X_train_selected).flatten()\n",
        "y_valid_pred = model.predict(X_valid_selected).flatten()\n",
        "y_test_pred = model.predict(X_test_selected).flatten()\n",
        "\n",
        "# Compute RÂ² Scores\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_valid = r2_score(y_valid, y_valid_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Train RÂ²: {r2_train:.4f}\")\n",
        "print(f\"Validation RÂ²: {r2_valid:.4f}\")\n",
        "print(f\"Test RÂ² (Out-of-Sample): {r2_test:.4f}\")\n"
      ],
      "metadata": {
        "id": "oj9Wr2s-WYQf",
        "outputId": "3f8c5572-4523-4ae9-8afd-8fc04f342d9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oj9Wr2s-WYQf",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 5.3907 - mae: 0.7567 - val_loss: 3.9183 - val_mae: 0.4973\n",
            "Epoch 2/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.6161 - mae: 0.4827 - val_loss: 2.6468 - val_mae: 0.3355\n",
            "Epoch 3/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.4730 - mae: 0.3648 - val_loss: 1.7387 - val_mae: 0.2260\n",
            "Epoch 4/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.6306 - mae: 0.2888 - val_loss: 1.1417 - val_mae: 0.1839\n",
            "Epoch 5/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.0625 - mae: 0.2286 - val_loss: 0.7671 - val_mae: 0.2021\n",
            "Epoch 6/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6859 - mae: 0.1919 - val_loss: 0.4790 - val_mae: 0.1556\n",
            "Epoch 7/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4332 - mae: 0.1531 - val_loss: 0.2918 - val_mae: 0.1008\n",
            "Epoch 8/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2789 - mae: 0.1347 - val_loss: 0.1772 - val_mae: 0.0759\n",
            "Epoch 9/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1769 - mae: 0.1080 - val_loss: 0.1062 - val_mae: 0.0600\n",
            "Epoch 10/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1088 - mae: 0.0918 - val_loss: 0.0642 - val_mae: 0.0470\n",
            "Epoch 11/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0686 - mae: 0.0756 - val_loss: 0.0402 - val_mae: 0.0505\n",
            "Epoch 12/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0434 - mae: 0.0677 - val_loss: 0.0255 - val_mae: 0.0468\n",
            "Epoch 13/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0258 - mae: 0.0556 - val_loss: 0.0155 - val_mae: 0.0497\n",
            "Epoch 14/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0108 - mae: 0.0247 - val_loss: 0.0105 - val_mae: 0.0479\n",
            "Epoch 15/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0063 - mae: 0.0228 - val_loss: 0.0093 - val_mae: 0.0527\n",
            "Epoch 16/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0038 - mae: 0.0216 - val_loss: 0.0109 - val_mae: 0.0583\n",
            "Epoch 17/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0024 - mae: 0.0208 - val_loss: 0.0117 - val_mae: 0.0613\n",
            "Epoch 18/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0017 - mae: 0.0206 - val_loss: 0.0106 - val_mae: 0.0610\n",
            "Epoch 19/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0013 - mae: 0.0207 - val_loss: 0.0094 - val_mae: 0.0609\n",
            "Epoch 20/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0204 - val_loss: 0.0105 - val_mae: 0.0629\n",
            "Epoch 21/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.5352e-04 - mae: 0.0203 - val_loss: 0.0119 - val_mae: 0.0668\n",
            "Epoch 22/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9.1453e-04 - mae: 0.0205 - val_loss: 0.0122 - val_mae: 0.0672\n",
            "Epoch 23/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.8958e-04 - mae: 0.0205 - val_loss: 0.0110 - val_mae: 0.0646\n",
            "Epoch 24/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.7314e-04 - mae: 0.0206 - val_loss: 0.0097 - val_mae: 0.0625\n",
            "Epoch 25/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.7306e-04 - mae: 0.0206 - val_loss: 0.0087 - val_mae: 0.0606\n",
            "Epoch 26/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.6249e-04 - mae: 0.0206 - val_loss: 0.0102 - val_mae: 0.0638\n",
            "Epoch 27/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.4648e-04 - mae: 0.0205 - val_loss: 0.0098 - val_mae: 0.0645\n",
            "Epoch 28/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.5954e-04 - mae: 0.0204 - val_loss: 0.0091 - val_mae: 0.0619\n",
            "Epoch 29/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.6007e-04 - mae: 0.0207 - val_loss: 0.0158 - val_mae: 0.0769\n",
            "Epoch 30/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.7694e-04 - mae: 0.0207 - val_loss: 0.0138 - val_mae: 0.0730\n",
            "Epoch 31/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.6158e-04 - mae: 0.0206 - val_loss: 0.0115 - val_mae: 0.0666\n",
            "Epoch 32/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.6144e-04 - mae: 0.0206 - val_loss: 0.0129 - val_mae: 0.0696\n",
            "Epoch 33/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.7425e-04 - mae: 0.0209 - val_loss: 0.0115 - val_mae: 0.0653\n",
            "Epoch 34/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.4928e-04 - mae: 0.0205 - val_loss: 0.0134 - val_mae: 0.0712\n",
            "Epoch 35/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.5802e-04 - mae: 0.0206 - val_loss: 0.0125 - val_mae: 0.0690\n",
            "Epoch 36/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.8695e-04 - mae: 0.0210 - val_loss: 0.0210 - val_mae: 0.0895\n",
            "Epoch 37/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.6259e-04 - mae: 0.0206 - val_loss: 0.0150 - val_mae: 0.0730\n",
            "Epoch 38/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.6378e-04 - mae: 0.0207 - val_loss: 0.0174 - val_mae: 0.0866\n",
            "Epoch 39/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.5328e-04 - mae: 0.0208 - val_loss: 0.0165 - val_mae: 0.0773\n",
            "Epoch 40/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.5625e-04 - mae: 0.0205 - val_loss: 0.0121 - val_mae: 0.0699\n",
            "Epoch 41/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.7391e-04 - mae: 0.0210 - val_loss: 0.0172 - val_mae: 0.0812\n",
            "Epoch 42/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.7816e-04 - mae: 0.0209 - val_loss: 0.0144 - val_mae: 0.0740\n",
            "Epoch 43/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.5569e-04 - mae: 0.0206 - val_loss: 0.0121 - val_mae: 0.0675\n",
            "Epoch 44/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.8115e-04 - mae: 0.0208 - val_loss: 0.0113 - val_mae: 0.0644\n",
            "Epoch 45/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7795e-04 - mae: 0.0207 - val_loss: 0.0148 - val_mae: 0.0744\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m67/67\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Train RÂ²: 0.2845\n",
            "Validation RÂ²: -1.7164\n",
            "Test RÂ² (Out-of-Sample): -25.7989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow scikit-learn pandas numpy matplotlib\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/OSEBX_Market_Macro_Data_2015_2024.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "df = df.dropna(subset=[\"OSEBXReturns\"])  # Drop missing target values\n",
        "\n",
        "features = [\n",
        "    \"Momentum_3M\", \"Momentum_6M\", \"Momentum_12M\",\n",
        "    \"Volatility_3M\", \"Volatility_6M\", \"Volatility_12M\",\n",
        "    \"Volume\", \"TurnoverRatio\", \"BidAskSpread\",\n",
        "    \"MarketCap\", \"DividendYield\", \"BookValuePerShare\",\n",
        "    \"EarningsPerShare\", \"Beta\", \"USDNOK\", \"EURNOK\",\n",
        "    \"US10Y\", \"USCPI\", \"USGDPGrowth\", \"NorgesBank10Y\", \"NorwegianCPI\",\n",
        "    \"BrentOil\"\n",
        "]\n",
        "\n",
        "target = \"OSEBXReturns\"\n",
        "df = df.dropna(subset=features)  # Drop missing feature values\n",
        "\n",
        "# Splitting data by year\n",
        "df = df.sort_values(by=\"Date\")\n",
        "train = df[(df[\"Date\"].dt.year >= 2015) & (df[\"Date\"].dt.year <= 2019)]\n",
        "valid = df[(df[\"Date\"].dt.year >= 2020) & (df[\"Date\"].dt.year <= 2022)]\n",
        "test = df[(df[\"Date\"].dt.year >= 2023)]\n",
        "\n",
        "X_train, y_train = train[features], train[target]\n",
        "X_valid, y_valid = valid[features], valid[target]\n",
        "X_test, y_test = test[features], test[target]\n",
        "\n",
        "# Standardizing features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Feature Selection using Elastic Net and Random Forest\n",
        "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "elastic_net.fit(X_train_scaled, y_train)\n",
        "elastic_net_importance = abs(elastic_net.coef_)\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "rf_importance = rf.feature_importances_\n",
        "\n",
        "# Select Top Features\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    \"Feature\": features,\n",
        "    \"ElasticNet Importance\": elastic_net_importance,\n",
        "    \"RandomForest Importance\": rf_importance\n",
        "})\n",
        "\n",
        "feature_importance_df[\"Avg Importance\"] = (feature_importance_df[\"ElasticNet Importance\"] + feature_importance_df[\"RandomForest Importance\"]) / 2\n",
        "feature_importance_df = feature_importance_df.sort_values(by=\"Avg Importance\", ascending=False)\n",
        "\n",
        "top_features = feature_importance_df[\"Feature\"].head(10).tolist()\n",
        "\n",
        "X_train_selected = pd.DataFrame(X_train_scaled, columns=features)[top_features]\n",
        "X_valid_selected = pd.DataFrame(X_valid_scaled, columns=features)[top_features]\n",
        "X_test_selected = pd.DataFrame(X_test_scaled, columns=features)[top_features]\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define NN1 (1 Hidden Layer)\n",
        "model_nn1 = keras.Sequential([\n",
        "    layers.Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(0.1), input_shape=(X_train_selected.shape[1],)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation=\"linear\")  # Output layer\n",
        "])\n",
        "\n",
        "# Define NN2 (2 Hidden Layers)\n",
        "model_nn2 = keras.Sequential([\n",
        "    layers.Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(0.1), input_shape=(X_train_selected.shape[1],)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(16, activation=\"relu\", kernel_regularizer=regularizers.l2(0.1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(1, activation=\"linear\")  # Output layer\n",
        "])\n",
        "\n",
        "# Compile Models\n",
        "for model in [model_nn1, model_nn2]:\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Early stopping for both models\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True)\n",
        "\n",
        "# Train NN1\n",
        "history_nn1 = model_nn1.fit(\n",
        "    X_train_selected, y_train,\n",
        "    validation_data=(X_valid_selected, y_valid),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train NN2\n",
        "history_nn2 = model_nn2.fit(\n",
        "    X_train_selected, y_train,\n",
        "    validation_data=(X_valid_selected, y_valid),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate NN1\n",
        "y_train_pred_nn1 = model_nn1.predict(X_train_selected).flatten()\n",
        "y_valid_pred_nn1 = model_nn1.predict(X_valid_selected).flatten()\n",
        "y_test_pred_nn1 = model_nn1.predict(X_test_selected).flatten()\n",
        "\n",
        "r2_train_nn1 = r2_score(y_train, y_train_pred_nn1)\n",
        "r2_valid_nn1 = r2_score(y_valid, y_valid_pred_nn1)\n",
        "r2_test_nn1 = r2_score(y_test, y_test_pred_nn1)\n",
        "\n",
        "# Evaluate NN2\n",
        "y_train_pred_nn2 = model_nn2.predict(X_train_selected).flatten()\n",
        "y_valid_pred_nn2 = model_nn2.predict(X_valid_selected).flatten()\n",
        "y_test_pred_nn2 = model_nn2.predict(X_test_selected).flatten()\n",
        "\n",
        "r2_train_nn2 = r2_score(y_train, y_train_pred_nn2)\n",
        "r2_valid_nn2 = r2_score(y_valid, y_valid_pred_nn2)\n",
        "r2_test_nn2 = r2_score(y_test, y_test_pred_nn2)\n",
        "\n",
        "# Print Results\n",
        "print(f\"NN1 Train RÂ²: {r2_train_nn1:.4f}\")\n",
        "print(f\"NN1 Validation RÂ²: {r2_valid_nn1:.4f}\")\n",
        "print(f\"NN1 Test RÂ² (Out-of-Sample): {r2_test_nn1:.4f}\")\n",
        "\n",
        "print(f\"NN2 Train RÂ²: {r2_train_nn2:.4f}\")\n",
        "print(f\"NN2 Validation RÂ²: {r2_valid_nn2:.4f}\")\n",
        "print(f\"NN2 Test RÂ² (Out-of-Sample): {r2_test_nn2:.4f}\")\n"
      ],
      "metadata": {
        "id": "hLarcgJEYdO7",
        "outputId": "b240babc-e8c9-4649-9cfb-6230f9316eff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hLarcgJEYdO7",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 4.4920 - mae: 1.2846 - val_loss: 4.1732 - val_mae: 0.7511\n",
            "Epoch 2/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.3924 - mae: 0.8251 - val_loss: 3.1543 - val_mae: 0.6351\n",
            "Epoch 3/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.6948 - mae: 0.6452 - val_loss: 2.2153 - val_mae: 0.6119\n",
            "Epoch 4/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1675 - mae: 0.4943 - val_loss: 1.5014 - val_mae: 0.5201\n",
            "Epoch 5/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8718 - mae: 0.4088 - val_loss: 1.1100 - val_mae: 0.4934\n",
            "Epoch 6/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.6179 - mae: 0.3171 - val_loss: 0.7856 - val_mae: 0.3631\n",
            "Epoch 7/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.4447 - mae: 0.2545 - val_loss: 0.5030 - val_mae: 0.2587\n",
            "Epoch 8/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.3156 - mae: 0.1918 - val_loss: 0.3432 - val_mae: 0.1895\n",
            "Epoch 9/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2258 - mae: 0.1498 - val_loss: 0.2428 - val_mae: 0.1563\n",
            "Epoch 10/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1618 - mae: 0.1143 - val_loss: 0.1565 - val_mae: 0.1290\n",
            "Epoch 11/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1151 - mae: 0.0867 - val_loss: 0.1080 - val_mae: 0.1060\n",
            "Epoch 12/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0802 - mae: 0.0654 - val_loss: 0.0695 - val_mae: 0.0837\n",
            "Epoch 13/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0564 - mae: 0.0492 - val_loss: 0.0502 - val_mae: 0.0695\n",
            "Epoch 14/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0400 - mae: 0.0403 - val_loss: 0.0354 - val_mae: 0.0629\n",
            "Epoch 15/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0279 - mae: 0.0320 - val_loss: 0.0250 - val_mae: 0.0525\n",
            "Epoch 16/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0273 - val_loss: 0.0186 - val_mae: 0.0520\n",
            "Epoch 17/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0136 - mae: 0.0250 - val_loss: 0.0147 - val_mae: 0.0547\n",
            "Epoch 18/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - mae: 0.0236 - val_loss: 0.0122 - val_mae: 0.0569\n",
            "Epoch 19/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0066 - mae: 0.0222 - val_loss: 0.0107 - val_mae: 0.0583\n",
            "Epoch 20/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0047 - mae: 0.0217 - val_loss: 0.0099 - val_mae: 0.0608\n",
            "Epoch 21/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0034 - mae: 0.0217 - val_loss: 0.0085 - val_mae: 0.0578\n",
            "Epoch 22/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0025 - mae: 0.0212 - val_loss: 0.0097 - val_mae: 0.0635\n",
            "Epoch 23/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0019 - mae: 0.0213 - val_loss: 0.0092 - val_mae: 0.0632\n",
            "Epoch 24/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0212 - val_loss: 0.0087 - val_mae: 0.0609\n",
            "Epoch 25/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0012 - mae: 0.0214 - val_loss: 0.0107 - val_mae: 0.0675\n",
            "Epoch 26/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0011 - mae: 0.0213 - val_loss: 0.0112 - val_mae: 0.0679\n",
            "Epoch 27/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9.9112e-04 - mae: 0.0214 - val_loss: 0.0105 - val_mae: 0.0635\n",
            "Epoch 28/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.2053e-04 - mae: 0.0213 - val_loss: 0.0116 - val_mae: 0.0667\n",
            "Epoch 29/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.9600e-04 - mae: 0.0215 - val_loss: 0.0119 - val_mae: 0.0712\n",
            "Epoch 30/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.7600e-04 - mae: 0.0215 - val_loss: 0.0122 - val_mae: 0.0700\n",
            "Epoch 31/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.5171e-04 - mae: 0.0214 - val_loss: 0.0118 - val_mae: 0.0673\n",
            "Epoch 32/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.4442e-04 - mae: 0.0213 - val_loss: 0.0132 - val_mae: 0.0681\n",
            "Epoch 33/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.1023e-04 - mae: 0.0210 - val_loss: 0.0126 - val_mae: 0.0666\n",
            "Epoch 34/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.2932e-04 - mae: 0.0212 - val_loss: 0.0160 - val_mae: 0.0745\n",
            "Epoch 35/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.2423e-04 - mae: 0.0213 - val_loss: 0.0132 - val_mae: 0.0691\n",
            "Epoch 36/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.2479e-04 - mae: 0.0212 - val_loss: 0.0129 - val_mae: 0.0686\n",
            "Epoch 37/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.1526e-04 - mae: 0.0211 - val_loss: 0.0151 - val_mae: 0.0710\n",
            "Epoch 38/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.2373e-04 - mae: 0.0213 - val_loss: 0.0168 - val_mae: 0.0770\n",
            "Epoch 39/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.2518e-04 - mae: 0.0213 - val_loss: 0.0183 - val_mae: 0.0843\n",
            "Epoch 40/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.6035e-04 - mae: 0.0215 - val_loss: 0.0153 - val_mae: 0.0768\n",
            "Epoch 41/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.3863e-04 - mae: 0.0216 - val_loss: 0.0162 - val_mae: 0.0759\n",
            "Epoch 1/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 6.4700 - mae: 1.3078 - val_loss: 7.4300 - val_mae: 1.4489\n",
            "Epoch 2/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.3982 - mae: 0.9408 - val_loss: 5.1743 - val_mae: 1.1200\n",
            "Epoch 3/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.2150 - mae: 0.6859 - val_loss: 4.2792 - val_mae: 1.0459\n",
            "Epoch 4/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.5210 - mae: 0.5518 - val_loss: 3.0495 - val_mae: 0.7743\n",
            "Epoch 5/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.9608 - mae: 0.4424 - val_loss: 2.4442 - val_mae: 0.6184\n",
            "Epoch 6/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.5271 - mae: 0.3651 - val_loss: 1.6895 - val_mae: 0.3655\n",
            "Epoch 7/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1642 - mae: 0.2858 - val_loss: 1.3314 - val_mae: 0.3149\n",
            "Epoch 8/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8944 - mae: 0.2296 - val_loss: 0.8938 - val_mae: 0.2222\n",
            "Epoch 9/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6892 - mae: 0.1846 - val_loss: 0.6740 - val_mae: 0.1999\n",
            "Epoch 10/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5216 - mae: 0.1452 - val_loss: 0.4907 - val_mae: 0.1538\n",
            "Epoch 11/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3972 - mae: 0.1185 - val_loss: 0.3562 - val_mae: 0.1218\n",
            "Epoch 12/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2995 - mae: 0.0956 - val_loss: 0.2595 - val_mae: 0.0979\n",
            "Epoch 13/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2251 - mae: 0.0746 - val_loss: 0.1870 - val_mae: 0.0737\n",
            "Epoch 14/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1693 - mae: 0.0588 - val_loss: 0.1414 - val_mae: 0.0665\n",
            "Epoch 15/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1273 - mae: 0.0469 - val_loss: 0.1051 - val_mae: 0.0534\n",
            "Epoch 16/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0961 - mae: 0.0409 - val_loss: 0.0787 - val_mae: 0.0437\n",
            "Epoch 17/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0726 - mae: 0.0354 - val_loss: 0.0612 - val_mae: 0.0476\n",
            "Epoch 18/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0550 - mae: 0.0306 - val_loss: 0.0472 - val_mae: 0.0443\n",
            "Epoch 19/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0420 - mae: 0.0267 - val_loss: 0.0371 - val_mae: 0.0440\n",
            "Epoch 20/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0323 - mae: 0.0248 - val_loss: 0.0295 - val_mae: 0.0443\n",
            "Epoch 21/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - mae: 0.0233 - val_loss: 0.0240 - val_mae: 0.0453\n",
            "Epoch 22/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0197 - mae: 0.0225 - val_loss: 0.0196 - val_mae: 0.0451\n",
            "Epoch 23/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0156 - mae: 0.0224 - val_loss: 0.0167 - val_mae: 0.0476\n",
            "Epoch 24/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0219 - val_loss: 0.0140 - val_mae: 0.0458\n",
            "Epoch 25/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0101 - mae: 0.0222 - val_loss: 0.0121 - val_mae: 0.0461\n",
            "Epoch 26/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - mae: 0.0220 - val_loss: 0.0102 - val_mae: 0.0450\n",
            "Epoch 27/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0067 - mae: 0.0223 - val_loss: 0.0093 - val_mae: 0.0464\n",
            "Epoch 28/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0055 - mae: 0.0222 - val_loss: 0.0085 - val_mae: 0.0477\n",
            "Epoch 29/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0045 - mae: 0.0222 - val_loss: 0.0083 - val_mae: 0.0507\n",
            "Epoch 30/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0220 - val_loss: 0.0075 - val_mae: 0.0488\n",
            "Epoch 31/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0223 - val_loss: 0.0075 - val_mae: 0.0506\n",
            "Epoch 32/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0220 - val_loss: 0.0078 - val_mae: 0.0533\n",
            "Epoch 33/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0022 - mae: 0.0218 - val_loss: 0.0074 - val_mae: 0.0536\n",
            "Epoch 34/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0019 - mae: 0.0216 - val_loss: 0.0073 - val_mae: 0.0529\n",
            "Epoch 35/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0016 - mae: 0.0215 - val_loss: 0.0081 - val_mae: 0.0571\n",
            "Epoch 36/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0214 - val_loss: 0.0092 - val_mae: 0.0622\n",
            "Epoch 37/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0013 - mae: 0.0213 - val_loss: 0.0097 - val_mae: 0.0634\n",
            "Epoch 38/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0012 - mae: 0.0211 - val_loss: 0.0094 - val_mae: 0.0629\n",
            "Epoch 39/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mae: 0.0211 - val_loss: 0.0092 - val_mae: 0.0639\n",
            "Epoch 40/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0010 - mae: 0.0210 - val_loss: 0.0104 - val_mae: 0.0678\n",
            "Epoch 41/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9.7707e-04 - mae: 0.0211 - val_loss: 0.0106 - val_mae: 0.0667\n",
            "Epoch 42/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.2837e-04 - mae: 0.0209 - val_loss: 0.0110 - val_mae: 0.0676\n",
            "Epoch 43/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1363e-04 - mae: 0.0210 - val_loss: 0.0109 - val_mae: 0.0641\n",
            "Epoch 44/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0704e-04 - mae: 0.0211 - val_loss: 0.0132 - val_mae: 0.0732\n",
            "Epoch 45/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0478e-04 - mae: 0.0212 - val_loss: 0.0124 - val_mae: 0.0693\n",
            "Epoch 46/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.7590e-04 - mae: 0.0210 - val_loss: 0.0129 - val_mae: 0.0674\n",
            "Epoch 47/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.6882e-04 - mae: 0.0208 - val_loss: 0.0134 - val_mae: 0.0702\n",
            "Epoch 48/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.6018e-04 - mae: 0.0210 - val_loss: 0.0136 - val_mae: 0.0722\n",
            "Epoch 49/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.6092e-04 - mae: 0.0208 - val_loss: 0.0130 - val_mae: 0.0695\n",
            "Epoch 50/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.6581e-04 - mae: 0.0210 - val_loss: 0.0179 - val_mae: 0.0782\n",
            "Epoch 51/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.4754e-04 - mae: 0.0209 - val_loss: 0.0177 - val_mae: 0.0828\n",
            "Epoch 52/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.5973e-04 - mae: 0.0209 - val_loss: 0.0133 - val_mae: 0.0673\n",
            "Epoch 53/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7135e-04 - mae: 0.0212 - val_loss: 0.0142 - val_mae: 0.0720\n",
            "Epoch 54/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.8147e-04 - mae: 0.0212 - val_loss: 0.0177 - val_mae: 0.0842\n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m67/67\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
            "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m67/67\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "NN1 Train RÂ²: 0.2050\n",
            "NN1 Validation RÂ²: -1.1024\n",
            "NN1 Test RÂ² (Out-of-Sample): -39.7467\n",
            "NN2 Train RÂ²: 0.1827\n",
            "NN2 Validation RÂ²: -1.0218\n",
            "NN2 Test RÂ² (Out-of-Sample): -32.9519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-load the dataset\n",
        "file_path = \"OSEBX_Market_Macro_Data_2015_2024.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Convert Date column to datetime format\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "\n",
        "# Drop rows with missing target variable (OSEBXReturns)\n",
        "df_clean = df.dropna(subset=[\"OSEBXReturns\"]).copy()\n",
        "\n",
        "# Selecting Features (X) and Target (Y)\n",
        "features = [\n",
        "    \"Momentum_3M\", \"Momentum_6M\", \"Momentum_12M\",\n",
        "    \"Volatility_3M\", \"Volatility_6M\", \"Volatility_12M\",\n",
        "    \"Volume\", \"TurnoverRatio\", \"BidAskSpread\",\n",
        "    \"MarketCap\", \"DividendYield\", \"BookValuePerShare\",\n",
        "    \"EarningsPerShare\", \"Beta\", \"USDNOK\", \"EURNOK\",\n",
        "    \"US10Y\", \"USCPI\", \"USGDPGrowth\", \"NorgesBank10Y\", \"NorwegianCPI\",\n",
        "    \"BrentOil\"\n",
        "]\n",
        "\n",
        "target = \"OSEBXReturns\"\n",
        "\n",
        "# Drop remaining rows with missing features\n",
        "df_clean = df_clean.dropna(subset=features)\n",
        "\n",
        "# Sorting dataset by Date\n",
        "df_clean = df_clean.sort_values(by=\"Date\")\n",
        "\n",
        "# Splitting data into training (2015-2019), validation (2020-2022), and test (2023-2024)\n",
        "train = df_clean[(df_clean[\"Date\"].dt.year >= 2015) & (df_clean[\"Date\"].dt.year <= 2019)]\n",
        "valid = df_clean[(df_clean[\"Date\"].dt.year >= 2020) & (df_clean[\"Date\"].dt.year <= 2022)]\n",
        "test = df_clean[(df_clean[\"Date\"].dt.year >= 2023)]\n",
        "\n",
        "# Extract features and target\n",
        "X_train, y_train = train[features], train[target]\n",
        "X_valid, y_valid = valid[features], valid[target]\n",
        "X_test, y_test = test[features], test[target]\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrame\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=features, index=X_train.index)\n",
        "X_valid_scaled = pd.DataFrame(X_valid_scaled, columns=features, index=X_valid.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=features, index=X_test.index)\n",
        "\n",
        "# Feature Selection using Elastic Net and Random Forest\n",
        "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "elastic_net.fit(X_train_scaled, y_train)\n",
        "elastic_net_importance = abs(elastic_net.coef_)\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "rf_importance = rf.feature_importances_\n",
        "\n",
        "# Select Top Features\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    \"Feature\": features,\n",
        "    \"ElasticNet Importance\": elastic_net_importance,\n",
        "    \"RandomForest Importance\": rf_importance\n",
        "})\n",
        "\n",
        "feature_importance_df[\"Avg Importance\"] = (feature_importance_df[\"ElasticNet Importance\"] + feature_importance_df[\"RandomForest Importance\"]) / 2\n",
        "feature_importance_df = feature_importance_df.sort_values(by=\"Avg Importance\", ascending=False)\n",
        "\n",
        "top_features = feature_importance_df[\"Feature\"].head(10).tolist()\n",
        "\n",
        "X_train_selected = X_train_scaled[top_features]\n",
        "X_valid_selected = X_valid_scaled[top_features]\n",
        "X_test_selected = X_test_scaled[top_features]\n",
        "\n",
        "# Import required libraries for XGBoost\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the XGBoost model with hyperparameter tuning\n",
        "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200, 500],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "    \"subsample\": [0.7, 1.0],\n",
        "    \"colsample_bytree\": [0.7, 1.0]\n",
        "}\n",
        "\n",
        "# Perform Grid Search with Cross-Validation\n",
        "grid_search = GridSearchCV(xgb_model, param_grid, cv=3, scoring=\"r2\", n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Get the best model from grid search\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate on training, validation, and test sets\n",
        "y_train_pred_xgb = best_xgb_model.predict(X_train_selected)\n",
        "y_valid_pred_xgb = best_xgb_model.predict(X_valid_selected)\n",
        "y_test_pred_xgb = best_xgb_model.predict(X_test_selected)\n",
        "\n",
        "# Compute R-squared scores\n",
        "r2_train_xgb = r2_score(y_train, y_train_pred_xgb)\n",
        "r2_valid_xgb = r2_score(y_valid, y_valid_pred_xgb)\n",
        "r2_test_xgb = r2_score(y_test, y_test_pred_xgb)\n",
        "\n",
        "# Results Summary\n",
        "{\n",
        "    \"XGBoost Train RÂ²\": r2_train_xgb,\n",
        "    \"XGBoost Validation RÂ²\": r2_valid_xgb,\n",
        "    \"XGBoost Test RÂ² (Out-of-Sample)\": r2_test_xgb\n",
        "}\n"
      ],
      "metadata": {
        "id": "TWpNsALiZl4X",
        "outputId": "e961e52a-2b01-4f8d-8f05-bc51672c2bb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TWpNsALiZl4X",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'XGBoost Train RÂ²': 0.4499276726254987,\n",
              " 'XGBoost Validation RÂ²': -0.0032004416905613287,\n",
              " 'XGBoost Test RÂ² (Out-of-Sample)': -0.023906247402601055}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}