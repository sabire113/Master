{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90c027c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data from: Cleaned_OSEFX_Market_Macro_Data.csv\n",
      "ERROR: File not found: Cleaned_OSEFX_Market_Macro_Data.csv\n",
      "Sorting and preparing columns...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# --- Data Preparation ---\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorting and preparing columns...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstrument\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# *** COLUMN CLEANING STEP ***\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Cleaning original column names...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# --- preprocess_data.py ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# *** DEFINE HELPER FUNCTION HERE ***\n",
    "def find_col(df, potential_names, default=None):\n",
    "    \"\"\"Helper to find the first matching column name from a list.\"\"\"\n",
    "    for name in potential_names:\n",
    "        if name in df.columns: return name\n",
    "    print(f\"  Warning: Could not find column using names: {potential_names}\") # Added warning\n",
    "    return default\n",
    "# *** END HELPER FUNCTION DEFINITION ***\n",
    "\n",
    "# --- Configuration ---\n",
    "INPUT_FILE = \"Cleaned_OSEFX_Market_Macro_Data.csv\"\n",
    "OUTPUT_FILE = \"Cleaned_OSEFX_Market_Macro_Data_PREPROCESSED.csv\" # Output for the pipeline\n",
    "TARGET_COL_NAME = \"TargetReturn_t+1\"         # Standard name for the pipeline\n",
    "NEXT_RAW_RET_COL_NAME = \"NextMonthlyReturn_t+1\" # Raw return for portfolio eval\n",
    "MKT_CAP_ORIG_COL_NAME = \"MarketCap_orig\"        # Original market cap for portfolio eval\n",
    "\n",
    "# --- Load Data ---\n",
    "print(f\"Loading raw data from: {INPUT_FILE}\")\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    print(f\"Raw data loaded. Shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found: {INPUT_FILE}\"); exit()\n",
    "except Exception as e:\n",
    "    print(f\"ERROR loading data: {e}\"); exit()\n",
    "\n",
    "# --- Data Preparation ---\n",
    "print(\"Sorting and preparing columns...\")\n",
    "df = df.sort_values(by=[\"Instrument\", \"Date\"]).reset_index(drop=True)\n",
    "\n",
    "# *** COLUMN CLEANING STEP ***\n",
    "print(\"  Cleaning original column names...\")\n",
    "df.columns = df.columns.str.replace(\"[^A-Za-z0-9_]+\", \"_\", regex=True).str.strip('_').str.replace('__', '_')\n",
    "# Find the potentially renamed columns AFTER cleaning\n",
    "norges_bank_10y_col = find_col(df, ['NorgesBank10Y', 'norgesbank10y']) # Helper function is now defined\n",
    "if not norges_bank_10y_col:\n",
    "    print(\"ERROR: Cannot find NorgesBank10Y column after cleaning.\")\n",
    "    exit()\n",
    "close_price_col = find_col(df, ['ClosePrice', 'closeprice'])\n",
    "common_shares_col = find_col(df, ['CommonSharesOutstanding', 'commonsharesoutstanding'])\n",
    "if not close_price_col or not common_shares_col:\n",
    "     print(f\"ERROR: Cannot find ClosePrice/CommonSharesOutstanding after cleaning.\")\n",
    "     exit()\n",
    "nibor3m_col = find_col(df, ['NIBOR3M', 'nibor3m'])\n",
    "if not nibor3m_col:\n",
    "    print(\"ERROR: Cannot find NIBOR3M column after cleaning.\")\n",
    "    exit()\n",
    "print(\"  Original column names cleaned.\")\n",
    "# *** END OF CLEANING AND FINDING RENAMED COLS ***\n",
    "\n",
    "# --- Continue with Calculations using found column names ---\n",
    "# Calculate Monthly Return (t) and Winsorize EARLY\n",
    "print(\"Calculating returns...\")\n",
    "df[\"MonthlyReturn_t\"] = df.groupby(\"Instrument\")[close_price_col].pct_change() # Use found name\n",
    "# ... (rest of return calculation as before) ...\n",
    "df[\"MonthlyReturn_t\"].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df[\"MonthlyReturn_t\"].fillna(0, inplace=True)\n",
    "df[\"MonthlyReturn_t\"] = winsorize(df[\"MonthlyReturn_t\"].values, limits=[0.01, 0.01])\n",
    "print(\"  MonthlyReturn_t calculated and winsorized.\")\n",
    "\n",
    "# Calculate Risk-Free Rate (t) using the cleaned column name\n",
    "df.loc[:, \"MonthlyRiskFreeRate_t\"] = df[norges_bank_10y_col] / 12 / 100 # Use found name\n",
    "print(\"  MonthlyRiskFreeRate_t calculated.\")\n",
    "\n",
    "# Calculate Adjusted Return (Excess Return for month t)\n",
    "df[\"AdjustedReturn_t\"] = df[\"MonthlyReturn_t\"] - df[\"MonthlyRiskFreeRate_t\"]\n",
    "print(\"  AdjustedReturn_t (Excess Return t) calculated.\")\n",
    "\n",
    "# --- Create Target and Necessary Lead Variables ---\n",
    "# *** NOW THESE COLUMNS WILL BE CREATED WITH '+' ***\n",
    "print(\"Calculating lead variables (Target and Next Raw Return)...\")\n",
    "df[TARGET_COL_NAME] = df.groupby(\"Instrument\")[\"AdjustedReturn_t\"].shift(-1)\n",
    "print(f\"  Target variable '{TARGET_COL_NAME}' created.\")\n",
    "df[NEXT_RAW_RET_COL_NAME] = df.groupby(\"Instrument\")[\"MonthlyReturn_t\"].shift(-1)\n",
    "print(f\"  Next raw return variable '{NEXT_RAW_RET_COL_NAME}' created.\")\n",
    "# *** END OF TARGET CREATION ***\n",
    "\n",
    "# Drop rows where the TARGET variable is NaN (essential!)\n",
    "initial_rows = len(df)\n",
    "df.dropna(subset=[TARGET_COL_NAME], inplace=True)\n",
    "print(f\"  Dropped {initial_rows - len(df)} rows with missing target '{TARGET_COL_NAME}'.\")\n",
    "if df.empty: print(\"ERROR: DataFrame empty after dropping missing target.\"); exit()\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "print(\"Performing feature engineering (Market Cap, Term Spread, Log Transforms)...\")\n",
    "# Recalculate MarketCap (t) using cleaned column names\n",
    "df[\"MarketCap\"] = df[close_price_col] * df[common_shares_col] # Use found names\n",
    "df.loc[df[\"MarketCap\"] <= 0, \"MarketCap\"] = np.nan\n",
    "df[MKT_CAP_ORIG_COL_NAME] = df[\"MarketCap\"].copy()\n",
    "print(f\"  MarketCap calculated and original stored in '{MKT_CAP_ORIG_COL_NAME}'.\")\n",
    "\n",
    "# Create term spread (t) using cleaned column names\n",
    "df[\"TermSpread\"] = df[norges_bank_10y_col] - df[nibor3m_col] # Use found names\n",
    "print(\"  TermSpread calculated.\")\n",
    "\n",
    "# Log-transform relevant variables (using potentially cleaned names)\n",
    "vars_to_log = [\"MarketCap\", \"BM\", \"ClosePrice\", \"Volume\", \"CommonSharesOutstanding\"]\n",
    "print(f\"  Log-transforming: {vars_to_log}\")\n",
    "for var in vars_to_log:\n",
    "    # Find the potentially cleaned column name - use more robust check now\n",
    "    potential_names = [var, var.lower(), var.replace(\"_\",\"\")] # Add different variations if needed\n",
    "    cleaned_var_name = find_col(df, potential_names)\n",
    "    if cleaned_var_name:\n",
    "        df[cleaned_var_name] = pd.to_numeric(df[cleaned_var_name], errors='coerce')\n",
    "        original_nan_mask = df[cleaned_var_name].isna()\n",
    "        log_col = f\"log_{cleaned_var_name}\" # Create log name based on found name\n",
    "        df[log_col] = np.nan\n",
    "        positive_mask = (~original_nan_mask) & (df[cleaned_var_name] > 1e-9)\n",
    "        df.loc[positive_mask, log_col] = np.log(df.loc[positive_mask, cleaned_var_name])\n",
    "        print(f\"    - Logged {positive_mask.sum()} positive values for {cleaned_var_name} -> {log_col}.\")\n",
    "    else:\n",
    "        print(f\"    - Warning: Column for '{var}' not found for log transform (using {potential_names}).\")\n",
    "\n",
    "\n",
    "# --- Final Checks and Save ---\n",
    "print(\"Final checks and saving preprocessed data...\")\n",
    "# Ensure essential ID/Date columns have standard names if possible\n",
    "if 'Instrument' not in df.columns and 'instrument' in df.columns:\n",
    "    df = df.rename(columns={'instrument': 'Instrument'})\n",
    "if 'Date' not in df.columns and 'date' in df.columns:\n",
    "    df = df.rename(columns={'date': 'Date'})\n",
    "\n",
    "# Verify essential columns exist before saving\n",
    "essential_final = ['Date', 'Instrument', TARGET_COL_NAME, NEXT_RAW_RET_COL_NAME, MKT_CAP_ORIG_COL_NAME]\n",
    "missing = [c for c in essential_final if c not in df.columns]\n",
    "if missing:\n",
    "    print(f\"ERROR: Essential columns missing before saving: {missing}\")\n",
    "    print(f\"Available columns: {df.columns.tolist()}\")\n",
    "    exit()\n",
    "\n",
    "# Drop rows where original market cap is non-positive or NaN\n",
    "initial_rows = len(df)\n",
    "df = df.dropna(subset=[MKT_CAP_ORIG_COL_NAME])\n",
    "df = df[df[MKT_CAP_ORIG_COL_NAME] > 0]\n",
    "rows_removed = initial_rows - len(df)\n",
    "if rows_removed > 0:\n",
    "    print(f\"  Dropped {rows_removed} rows with missing or non-positive '{MKT_CAP_ORIG_COL_NAME}'.\")\n",
    "\n",
    "if df.empty: print(\"ERROR: DataFrame empty after final checks.\"); exit()\n",
    "\n",
    "# Convert numeric columns to float32\n",
    "numeric_cols_final = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_cols_final] = df[numeric_cols_final].astype(\"float32\")\n",
    "\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"Preprocessing complete. Final shape: {df.shape}\")\n",
    "print(f\"Preprocessed data saved to: {OUTPUT_FILE}\")\n",
    "print(\"\\nFinal Data Info:\")\n",
    "df.info(verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
